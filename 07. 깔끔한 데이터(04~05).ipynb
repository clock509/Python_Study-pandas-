{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-4. 중복 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n",
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "#artist, track, time, date.enterd열의 데이터가 반복되는 빌보드 차트 데이터!\n",
    "import pandas as pd\n",
    "\n",
    "billboard = pd.read_csv(\"./data/billboard.csv\")\n",
    "billboard_long = pd.melt(billboard, \n",
    "                         id_vars = ['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "                         var_name = 'week',\n",
    "                         value_name = 'rating')\n",
    "\n",
    "print(billboard_long.shape)\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "#노래 제목이 Loser인 데이터만 모아보면, 중복 데이터가 꽤 많은 걸 알 수 있다.\n",
    "\n",
    "print(billboard_long[billboard_long.track == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "#중복데이터 : year, artist, track, time, date\n",
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']]\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "#중복 데이터 제거: drop_duplicates\n",
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "#중복 제거 완료.\n",
    "#이제는 데이터프레임에 id도 추가.   ==> id를 추가하면 데이터를 쉽게 조회, 구분 가능.\n",
    "billboard_songs['id'] = range(len(billboard_songs))\n",
    "print(billboard_songs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n",
      "   year artist                    track  time date.entered week  rating  id\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0   0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk2    82.0   0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk3    72.0   0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk4    77.0   0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk5    87.0   0\n"
     ]
    }
   ],
   "source": [
    "#merge 메서드를 사용해 노래 정보와 주간 순위 데이터를 합침.\n",
    "billboard_ratings = billboard_long.merge(billboard_songs, on = ['year', 'artist', 'track', 'time'])\n",
    "print(billboard_ratings.shape)\n",
    "\n",
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-5. 대용량 데이터 처리하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 개로 나누어진 데이터 불러오기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-01.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-02.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-02.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-03.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-03.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-04.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-04.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-05.csv\n",
      "\n",
      "./data\\fhv_tripdata_2015-05.csv\n"
     ]
    }
   ],
   "source": [
    "#뉴욕 택시 데이터: 13억대의 뉴욕 택시에 대한 정보, 140개 파일.\n",
    "#이 중 5개의 데이터만 다운받아 사용해 보겠다.\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "with open('./data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', './data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data\\\\fhv_tripdata_2015-01.csv', './data\\\\fhv_tripdata_2015-02.csv', './data\\\\fhv_tripdata_2015-03.csv', './data\\\\fhv_tripdata_2015-04.csv', './data\\\\fhv_tripdata_2015-05.csv']\n"
     ]
    }
   ],
   "source": [
    "#glob 메서드: 특정한 패턴의 이름을 가진 파일을 한 번에 읽어들임.\n",
    "#glob으로 5개의 파일 불러오기..\n",
    "import glob\n",
    "nyc_taxi_data = glob.glob('./data/fhv_*')\n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그 후 각각의 파일을 데이터프레임으로 저장\n",
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n"
     ]
    }
   ],
   "source": [
    "print(taxi1.head(2))\n",
    "print(taxi2.head(2))\n",
    "print(taxi3.head(2))\n",
    "print(taxi4.head(2))\n",
    "print(taxi5.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2746033, 3)\n",
      "(3126401, 3)\n",
      "(3281427, 3)\n",
      "(3917789, 3)\n",
      "(4296067, 3)\n"
     ]
    }
   ],
   "source": [
    "#데이터 구조 확인.\n",
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "#각 데이터프레임 연결하기: concat 메서드\n",
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "2               B00013  2015-01-01 01:23:00         NaN\n",
      "3               B00013  2015-01-01 01:44:00         NaN\n",
      "4               B00013  2015-01-01 02:00:00         NaN\n",
      "(17367717, 3)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Tip. 반복문을 사용하여 단 몇 줄만으로 데이터 준비하기\n",
    "#앞에서 생성한 파일 목록(nyc_taxi_data)을 읽어들여 리스트(list_taxi_df)에 이어붙임.\n",
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "    #print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df)\n",
    "\n",
    "print(len(list_taxi_df))   #불러들어온 파일 개수 확인\n",
    "\n",
    "print(type(list_taxi_df[0]))\n",
    "\n",
    "print(list_taxi_df[0].head())\n",
    "\n",
    "taxi_loop_concat = pd.concat(list_taxi_df) #리스트(list_taxi_df)에 5개의 파일들을 이어붙임.\n",
    "print(taxi_loop_concat.shape)\n",
    "\n",
    "print(taxi.equals(taxi_loop_concat))       #위에서 생성한 taxi와 taxi_loop_concat 같은가 확인."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
