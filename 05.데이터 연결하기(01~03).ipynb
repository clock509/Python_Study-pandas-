{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-1. 분석하기 좋은 데이터\n",
    "- 분석하기 좋은 데이터: 깔끔한 데이터(Tidy data)\n",
    "-   조건 1. 데이터 분석 목적에 맞는 데이터를 모아 새로운 표(table)을 만들어아 한다.\n",
    "-   조건 2. 측정한 값은 행(row)를 구성해야 한다.\n",
    "-   조건 3. 변수는 열(column)로 구성해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-2. 데이터 연결 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. concat method: 데이터 연결\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('./data/concat_1.csv')\n",
    "df2 = pd.read_csv('./data/concat_2.csv')\n",
    "df3 = pd.read_csv('./data/concat_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#2. 연결한 데이터 프레임 출력: concat 메서드에 연결하려는 데이터프레임을 리스트에 담아서 전달\n",
    "\n",
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3. 특정 행의 데이터 추출\n",
    "print(row_concat.iloc[3, ])  #iloc = index lcation #3번째 행의 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 데이터프레임에 시리즈 연결하기\n",
    "#   1)리스트를 시리즈로 변환\n",
    "new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "#5. concat 메서드로 row_concat와 new_row_series 시리즈 연결\n",
    "print(pd.concat([df1, new_row_series]))  #시리즈는 열로 붙으면서 NaN이 뜬다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행 1개로 구성된 데이터프레임 생성하여 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "#1. 시리즈에는 열 이름이 없기 때문에 새로운 열로 간주되어 0이라는 이름의 열로 추가됨.\n",
    "#   그러므로, 행이 1개라도 반드시 데이터프레임에 담은 후 연결해야 함.\n",
    "\n",
    "new_row_df = pd.DataFrame([['n1', 'n2', 'n3', 'n4']], columns = ['A', 'B', 'C', 'D'])\n",
    "print(new_row_df)\n",
    "print()\n",
    "print(pd.concat([df1, new_row_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "#2. concat는 한 번에 2개 이상의 DataFrame 연결 가능.\n",
    "#연결할 데이터프레임이 1개라면 append 메서드를 사용해도 됨.\n",
    "print(df1.append(new_row_df))   #단순히 연결하는 것이므로 4번째 인덱스가 그대로 0으로 출력됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "#3. append 메서드와 dictionary의 결합\n",
    "#ignore_index를 True로 설장하면, 데이터 연결 후 인덱스를 0부터 다시 지정\n",
    "\n",
    "data_dict = {'A': 'n1', 'B': 'n2', 'C': 'n3', 'D': 'n4'}\n",
    "print(df1.append(data_dict, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다양한 방법으로 데이터 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#1. ignore_index인자 사용\n",
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index = True)\n",
    "print(row_concat_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#2. 열 방향으로 데이터 연결하기: concat에 axis=1 추가해주기\n",
    "col_concat = pd.concat([df1, df2, df3], axis = 1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n"
     ]
    }
   ],
   "source": [
    "#3. 같은 열 이름이 있는 데이터프레임에서 열 이름으로 데이터를 추출하면?\n",
    "print(col_concat['A'])    #해당 열 이름의 데이터를 모두 출력!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4\n"
     ]
    }
   ],
   "source": [
    "#4. 간편하게 새로운 열 추가하기\n",
    "col_concat['new_col_list'] = ['n1', 'n2', 'n3', 'n4']\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#5. 새 컬럼 추가 후 열 이름 재지정: ignore_index를 True로 지정\n",
    "print(pd.concat([df1, df2, df3], axis = 1, ignore_index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    E   F   G   H\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#6. 공통 열과 공통 인덱스만 연결하기\n",
    "#컬럼명 재지정\n",
    "df1.columns = ['A', 'B', 'C', 'D']\n",
    "df2.columns = ['E', 'F', 'G', 'H']\n",
    "df3.columns = ['A', 'C', 'F', 'H']\n",
    "print(df1)\n",
    "print(type(df1))\n",
    "\n",
    "print(df2)\n",
    "print(type(df2))\n",
    "\n",
    "print(df3)\n",
    "print(type(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "0  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "1  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "2  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "3  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "1   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "2  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "3  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n"
     ]
    }
   ],
   "source": [
    "#7. 컬럼명 재지정한 데이터프레임들 연결하기\n",
    "row_concat = pd.concat([df1, df2, df3], sort = True)\n",
    "print(row_concat)  #공통 열들에만 데이터가 들어가고, 없는 열 이름의 데이터는 NaN 처리됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#8. 공통 열만 골라서 연결하려면, join 인자를 inner로 지정\n",
    "\n",
    "print(pd.concat([df1, df2, df3], join = 'inner'))  #df1 ~ df3의 공통열이 없으므로 빈 데이터프레임이 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n"
     ]
    }
   ],
   "source": [
    "#9.\n",
    "print(pd.concat([df1, df3], ignore_index = False, join = 'inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "\n",
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7 \n",
      "\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#10. 행 방향으로 연결하기.\n",
    "\n",
    "#인덱스 재지정\n",
    "df1.index = [0, 1, 2, 3]\n",
    "df2.index = [4, 5, 6, 7]\n",
    "df3.index = [0, 2, 5, 7]\n",
    "\n",
    "print(df1, '\\n')\n",
    "print(df2, '\\n')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#11. df1 ~ df3 행 방향으로 연결: concat\n",
    "col_concat = pd.concat([df1, df2, df3], axis = 1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "#12. 공통 행만 골라 연결\n",
    "print(pd.concat([df1, df3], axis = 1, join = 'inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inner join VS outer join\n",
    "- inner join: 둘 이상의 데이터프레임에서 조건에 맞는 행을 연결하는 것.\n",
    "- outer join: Left outer join, Right outer join, Full outer join\n",
    "    * Left outer join: 왼쪽 데이터프레임 모두 포함하여 연결\n",
    "    * Right outer join: 오른쪽 데이터프레임 모두 포함하여 연결\n",
    "    * Full outer join: 왼쪽, 오른쪽 모두 포함하여 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-3. 데이터 연결 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge 메소드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n",
      "\n",
      "     name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "\n",
      "    ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n",
      "\n",
      "     taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "#1. 특정 위치의 날씨 정보 데이터 만들기\n",
    "\n",
    "person = pd.read_csv('./data/survey_person.csv')\n",
    "site = pd.read_csv('./data/survey_site.csv')\n",
    "survey = pd.read_csv('./data/survey_survey.csv')\n",
    "visited = pd.read_csv('./data/survey_visited.csv')\n",
    "\n",
    "print(person)\n",
    "\n",
    "print(\"\\n\", site)\n",
    "\n",
    "print(\"\\n\", visited)\n",
    "\n",
    "print(\"\\n\", survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. vistied 데이터프레임의 일부 데이터만 떼어내기\n",
    "visited_subset = visited.loc[[0, 2, 6], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#3. merge : inner join을 기본으로 실행함\n",
    "#메서드를 사용한 데이터프레임(site)을 왼쪽으로 지정하고, \n",
    "#첫 번째 인자값으로 지정한 데이터프레임(visited_subset)을 오른쪽으로 지정.\n",
    "#left_on, right_on: 값이 일치해야 할 왼쪽과 오른쪽 데이터프레임의 열을 지정\n",
    "#즉, site의 열(name)과 visited의 열(site)의 값이 일치하면 왼쪽 데이터프레임(site)을 기준으로 연결함.\n",
    "o2o_merge = site.merge(visited_subset, left_on = 'name', right_on = 'site')\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#4. site, visited 데이터프레임을 이용하여 데이터 연결\n",
    "m2o_merge = site.merge(visited, left_on = 'name', right_on = 'site')\n",
    "print(m2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   personal   family  taken person quant  reading\n",
      "0   dyer    William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer    William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer    William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer    William     Dyer    622   dyer   sal     0.09\n",
      "4     pb      Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb      Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb      Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb      Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb      Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake   Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake   Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake   Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake   Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake   Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake   Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake   Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentina  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentina  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentina  Roerich    844    roe   rad    11.25\n",
      "\n",
      "     ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3         NaN    752   lake   rad     2.19\n",
      "14    752   DR-3         NaN    752   lake   sal     0.09\n",
      "15    752   DR-3         NaN    752   lake  temp   -16.00\n",
      "16    752   DR-3         NaN    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "#5. person, survey 를  visited, survey를 merge로 연결.\n",
    "ps = person.merge(survey, left_on = 'ident', right_on = 'person') #person의 ident와 survey의 person이 같은 것\n",
    "vs = visited.merge(survey, left_on = 'ident', right_on = 'taken') #visited의 ident와 survey의 taken이 같은 것\n",
    "\n",
    "print(ps)\n",
    "print(\"\\n\", vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident_x   personal   family  taken_x person_x quant  reading  ident_y  \\\n",
      "0     dyer    William     Dyer      619     dyer   rad     9.82      619   \n",
      "1     dyer    William     Dyer      619     dyer   sal     0.13      619   \n",
      "2     dyer    William     Dyer      622     dyer   rad     7.80      622   \n",
      "3     dyer    William     Dyer      622     dyer   sal     0.09      622   \n",
      "4       pb      Frank  Pabodie      734       pb   rad     8.41      734   \n",
      "5       pb      Frank  Pabodie      734       pb  temp   -21.50      734   \n",
      "6       pb      Frank  Pabodie      735       pb   rad     7.22      735   \n",
      "7       pb      Frank  Pabodie      751       pb   rad     4.35      751   \n",
      "8       pb      Frank  Pabodie      751       pb  temp   -18.50      751   \n",
      "9     lake   Anderson     Lake      734     lake   sal     0.05      734   \n",
      "10    lake   Anderson     Lake      751     lake   sal     0.10      751   \n",
      "11    lake   Anderson     Lake      752     lake   rad     2.19      752   \n",
      "12    lake   Anderson     Lake      752     lake   sal     0.09      752   \n",
      "13    lake   Anderson     Lake      752     lake  temp   -16.00      752   \n",
      "14    lake   Anderson     Lake      837     lake   rad     1.46      837   \n",
      "15    lake   Anderson     Lake      837     lake   sal     0.21      837   \n",
      "16     roe  Valentina  Roerich      752      roe   sal    41.60      752   \n",
      "17     roe  Valentina  Roerich      837      roe   sal    22.50      837   \n",
      "18     roe  Valentina  Roerich      844      roe   rad    11.25      844   \n",
      "\n",
      "     site       dated  taken_y person_y  \n",
      "0    DR-1  1927-02-08      619     dyer  \n",
      "1    DR-1  1927-02-08      619     dyer  \n",
      "2    DR-1  1927-02-10      622     dyer  \n",
      "3    DR-1  1927-02-10      622     dyer  \n",
      "4    DR-3  1939-01-07      734       pb  \n",
      "5    DR-3  1939-01-07      734       pb  \n",
      "6    DR-3  1930-01-12      735       pb  \n",
      "7    DR-3  1930-02-26      751       pb  \n",
      "8    DR-3  1930-02-26      751       pb  \n",
      "9    DR-3  1939-01-07      734     lake  \n",
      "10   DR-3  1930-02-26      751     lake  \n",
      "11   DR-3         NaN      752     lake  \n",
      "12   DR-3         NaN      752     lake  \n",
      "13   DR-3         NaN      752     lake  \n",
      "14  MSK-4  1932-01-14      837     lake  \n",
      "15  MSK-4  1932-01-14      837     lake  \n",
      "16   DR-3         NaN      752      roe  \n",
      "17  MSK-4  1932-01-14      837      roe  \n",
      "18   DR-1  1932-03-22      844      roe  \n",
      "ident_x           dyer\n",
      "personal       William\n",
      "family            Dyer\n",
      "taken_x            619\n",
      "person_x          dyer\n",
      "quant              rad\n",
      "reading           9.82\n",
      "ident_y            619\n",
      "site              DR-1\n",
      "dated       1927-02-08\n",
      "taken_y            619\n",
      "person_y          dyer\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#6. 여러 개의 컬럼을 리스트에 담아 전달해도 됨.\n",
    "ps_vs = ps.merge(vs, left_on = ['ident', 'taken', 'quant', 'reading'], right_on = ['person', 'ident', 'quant', 'reading'])\n",
    "print(ps_vs)           #ps와 vs에 공통적으로 있는 열 이름(ident, taken, person)은 접미사가 추가되어있음\n",
    "#                      (_x: 왼쪽 데이터프레임, _y: 오른쪽 데이터프레임 )\n",
    "print(ps_vs.loc[0, ])  #0행 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#누락값, 중복값 해결이 데이터 분석의 기초!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
